{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.set_printoptions(threshold=10000, suppress = True) \n",
    "import pandas as pd \n",
    "import warnings \n",
    "import matplotlib.pyplot as plt \n",
    "warnings.filterwarnings('ignore')\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "from utilsfunction import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import importlib, utilsfunction\n",
    "importlib.reload(utilsfunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('PubMed-multi-label-dataset.csv', sep=\",\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drop = data.drop(columns=['Title', 'meshMajor', 'pmid', \"meshid\", 'meshroot'])\n",
    "\n",
    "# Suppression des stopwords\n",
    "data_drop['abstractText'] = data_drop['abstractText'].apply(lambda x: remove_stopwords(x) if isinstance(x, str) else x)\n",
    "# Mise en minuscule\n",
    "data_drop['abstractText'] = data_drop['abstractText'].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "# Suppression des ponctuations\n",
    "data_drop['abstractText'] = data_drop['abstractText'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)) if isinstance(x, str) else x)\n",
    "\n",
    "data_drop.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des données en données d'entrainement et de test 50-50\n",
    "data_features = data_drop['abstractText']\n",
    "data_labels = data_drop.drop(columns=['abstractText'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_features, data_labels, test_size=0.5, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=3000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = run_models(X_train_tfidf, y_train, X_test_tfidf, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
